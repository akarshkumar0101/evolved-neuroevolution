{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "stunning-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "advanced-graduate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1097da690>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 5000\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "vietnamese-development",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                                 ])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./mnist/', train=True, download=True,\n",
    "                             transform=transform),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./', train=False, download=True,\n",
    "                             transform=transform),\n",
    "    batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "crazy-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.NLLLoss()\n",
    "def perform_stats(net, loader=test_loader, show_stats=True, n_batches=-1, tqdm=tqdm):\n",
    "    n_correct, total = 0, 0\n",
    "    loss_total = 0\n",
    "    n_examples = 0\n",
    "    loop = enumerate(loader)\n",
    "    if tqdm is not None:\n",
    "        loop = tqdm(loop, leave=False, total=max(n_batches, len(loader)))\n",
    "    for batch_idx, (X_batch, Y_batch) in loop:\n",
    "        if batch_idx == n_batches:\n",
    "            break\n",
    "        Y_batch_pred = net(X_batch)\n",
    "        n_correct += (Y_batch_pred.argmax(dim=-1)==Y_batch).sum().item()\n",
    "        loss = loss_func(Y_batch_pred.log(), Y_batch).item()\n",
    "        loss_total += loss * len(X_batch)\n",
    "        n_examples += len(X_batch)\n",
    "        total += len(Y_batch)\n",
    "    loss_total /= n_examples\n",
    "    accuracy = n_correct/total\n",
    "    if show_stats:\n",
    "        print(f'Average Loss: {loss_total:.03f}, Accuracy: {accuracy*100:.03f}%')\n",
    "    return loss_total, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "earlier-handling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Kernel Shape\n",
       "============================================================================================================================================\n",
       "ConvNet                                  --                        --                        --                        --\n",
       "├─Conv2d: 1-1                            [64, 1, 28, 28]           [64, 2, 26, 26]           20                        [1, 2, 3, 3]\n",
       "├─Conv2d: 1-2                            [64, 2, 13, 13]           [64, 5, 11, 11]           95                        [2, 5, 3, 3]\n",
       "├─Conv2d: 1-3                            [64, 5, 5, 5]             [64, 10, 3, 3]            460                       [5, 10, 3, 3]\n",
       "├─Conv2d: 1-4                            [64, 10, 1, 1]            [64, 10, 1, 1]            110                       [10, 10, 1, 1]\n",
       "├─Linear: 1-5                            [64, 10]                  [64, 10]                  110                       [10, 10]\n",
       "============================================================================================================================================\n",
       "Total params: 795\n",
       "Trainable params: 795\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 1.75\n",
       "============================================================================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 1.06\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 1.26\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 2, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(2, 5, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(5, 10, kernel_size=3)\n",
    "        self.conv4 = nn.Conv2d(10, 10, kernel_size=1)\n",
    "        self.fc1 = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(torch.max_pool2d(self.conv1(x), 2))\n",
    "        x = torch.relu(torch.max_pool2d(self.conv2(x), 2))\n",
    "        x = torch.relu(torch.max_pool2d(self.conv3(x), 2))\n",
    "        x = torch.relu(self.conv4(x))\n",
    "        x = x.view(-1, 10)\n",
    "        x = self.fc1(x)\n",
    "        return x.softmax(dim=-1)\n",
    "    \n",
    "    \n",
    "net = ConvNet()\n",
    "summary_kwargs = {'input_size': (batch_size_train, 1, 28, 28), \n",
    "                  'col_names': [\"input_size\", \"output_size\", \"num_params\", \"kernel_size\"]}\n",
    "summary(net, **summary_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "billion-sugar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 2.340, Accuracy: 10.100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.340292453765869, 0.101)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perform_stats(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "brown-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = torch.optim.SGD(net.parameters(), lr=1e-3)\n",
    "opt = torch.optim.Adam(net.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "representative-albany",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a31109785b484790161c39a0bd5b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a869a2baff2945619770997d300ad8f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-295cb8d9dafd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     for batch_idx, (X_batch, Y_batch) in tqdm(enumerate(train_loader), \n\u001b[0m\u001b[1;32m      3\u001b[0m                                               leave=False, total=len(train_loader)):\n\u001b[1;32m      4\u001b[0m         \u001b[0mY_batch_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_batch_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \"\"\"\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;31m# put it from HWC to CHW format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_float_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(n_epochs)):\n",
    "    for batch_idx, (X_batch, Y_batch) in tqdm(enumerate(train_loader), \n",
    "                                              leave=False, total=len(train_loader)):\n",
    "        Y_batch_pred = net(X_batch)\n",
    "        loss = loss_func(Y_batch_pred.log(), Y_batch)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    perform_stats(net)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "essential-latex",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.nn.utils.parameters_to_vector(net.parameters())\n",
    "torch.nn.utils.vector_to_parameters(v, net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "alleged-fiber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Sequential                               --\n",
       "├─Linear: 1-1                            69,700\n",
       "├─Sigmoid: 1-2                           --\n",
       "├─Linear: 1-3                            10,100\n",
       "├─Sigmoid: 1-4                           --\n",
       "├─Linear: 1-5                            10,100\n",
       "├─Sigmoid: 1-6                           --\n",
       "├─Linear: 1-7                            10,100\n",
       "├─Sigmoid: 1-8                           --\n",
       "├─Linear: 1-9                            10,100\n",
       "├─Sigmoid: 1-10                          --\n",
       "├─Linear: 1-11                           10,100\n",
       "├─Sigmoid: 1-12                          --\n",
       "├─Linear: 1-13                           10,100\n",
       "├─Sigmoid: 1-14                          --\n",
       "├─Linear: 1-15                           70,296\n",
       "=================================================================\n",
       "Total params: 200,596\n",
       "Trainable params: 200,596\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conet = nn.Sequential(\n",
    "    nn.Linear(len(v)*2, 100),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(100, 100),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(100, 100),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(100, 100),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(100, 100),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(100, 100),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(100, 100),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(100, len(v)*2),\n",
    ")\n",
    "munet = nn.Sequential(\n",
    "    nn.Linear(len(v), 100),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(100, 50),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(50, 100),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(100, len(v)),\n",
    ")\n",
    "summary(conet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "polished-privilege",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "prescription-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_idx, (X_batch, Y_batch) = next(enumerate(train_loader))\n",
    "def calc_pheo_fitness(net):\n",
    "    Y_batch_pred = net(X_batch)\n",
    "    n_correct = (Y_batch_pred.argmax(dim=-1)==Y_batch).sum().item()\n",
    "    loss = loss_func(Y_batch_pred.log(), Y_batch).item()\n",
    "    accuracy = n_correct/len(Y_batch)\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "collect-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.tensorboard as tb\n",
    "import os\n",
    "# import tempfile\n",
    "# tb_log_dir = tempfile.mkdtemp()\n",
    "user = os.getlogin()\n",
    "# tb_log_dir = os.path.join(cp.data_dir, 'tensorboard/', user)\n",
    "tb_log_dir = f'/tmp/tensorboard/{user}'\n",
    "# print(tb_log_dir)\n",
    "import shutil\n",
    "if os.path.exists(tb_log_dir):\n",
    "    shutil.rmtree(tb_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "stuffed-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "logger = SummaryWriter(tb_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "complimentary-indianapolis",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409b3864b2ca461dbd163d2bbb32939c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agent = ConvNet()\n",
    "\n",
    "def to_np_array(population):\n",
    "    pop = np.empty(len(population), dtype=object)\n",
    "    for i in range(len(pop)):\n",
    "        pop[i] = population[i]\n",
    "    return pop\n",
    "\n",
    "def get_init_population():\n",
    "    pop = [nn.utils.parameters_to_vector(ConvNet().parameters()).detach() for _ in range(100)]\n",
    "    pop = to_np_array(pop)\n",
    "    return pop\n",
    "\n",
    "def geno2pheno():\n",
    "    pass\n",
    "def pheno2geno():\n",
    "    pass\n",
    "\n",
    "def calc_fitnesses(population):\n",
    "    fitnesses = []\n",
    "    fitnesses_acc = []\n",
    "    for dna in population:\n",
    "        nn.utils.vector_to_parameters(dna, agent.parameters())\n",
    "#         fitness = -perform_stats(agent, train_loader, n_batches=1, show_stats=False, tqdm=None)[0]\n",
    "        nll, acc = calc_pheo_fitness(agent)\n",
    "        fitnesses.append(-nll)\n",
    "        fitnesses_acc.append(acc)\n",
    "    return fitnesses, fitnesses_acc\n",
    "\n",
    "def calc_mutate(pop):\n",
    "    mutant = [d+1e-2*torch.randn_like(d) for d in pop]\n",
    "    return mutant\n",
    "\n",
    "def calc_crossover(pop1, pop2):\n",
    "    cross = [torch.stack([d1, d2], dim=0).mean(dim=0) for d1, d2 in zip(pop1, pop2)]\n",
    "    return cross\n",
    "    \n",
    "def calc_next_population(population, fitnesses):\n",
    "    npop = []\n",
    "    npop.append(population[np.argmax(fitnesses)])\n",
    "    prob = torch.tensor(fitnesses).softmax(dim=-1).numpy()\n",
    "    \n",
    "    n_parents = 29\n",
    "    n_mutants = 70\n",
    "    \n",
    "    mutants = np.random.choice(population, size=n_mutants, p=prob)\n",
    "    mutants = calc_mutate(mutants)\n",
    "    parents1 = np.random.choice(population, size=n_parents, p=prob)\n",
    "    parents2 = np.random.choice(population, size=n_parents, p=prob)\n",
    "    children = calc_crossover(parents1, parents2)\n",
    "    \n",
    "    npop.extend(mutants)\n",
    "    npop.extend(children)\n",
    "    \n",
    "    npop = to_np_array(npop)\n",
    "    return npop\n",
    "    \n",
    "    \n",
    "\n",
    "population = get_init_population()\n",
    "for gen_idx in tqdm(range(10000)):\n",
    "    fitnesses, fitnesses_acc = calc_fitnesses(population)\n",
    "    data =  {'fitness max': np.max(fitnesses),\n",
    "             'fitness mean': np.mean(fitnesses),\n",
    "             'fitness med': np.median(fitnesses)}\n",
    "    logger.add_scalars('fitness', data, global_step=gen_idx)\n",
    "    data =  {'fitness max': np.max(fitnesses_acc),\n",
    "             'fitness mean': np.mean(fitnesses_acc),\n",
    "             'fitness med': np.median(fitnesses_acc)}\n",
    "    logger.add_scalars('accuracies', data, global_step=gen_idx)\n",
    "    logger.add_histogram('fitness histogram', np.array(fitnesses), global_step=gen_idx)\n",
    "    logger.add_histogram('accuracies histogram', np.array(fitnesses_acc), global_step=gen_idx)\n",
    "    population = calc_next_population(population, fitnesses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "optimum-bernard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([795])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-stock",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-scholarship",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-tolerance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-breeding",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-editing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-curtis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-fetish",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-issue",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-deposit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-cleaner",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-purple",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-surprise",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-shoulder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-graham",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-australian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-writing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "successful-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from types import ModuleType, FunctionType\n",
    "from gc import get_referents\n",
    "\n",
    "# Custom objects know their class.\n",
    "# Function objects seem to know way too much, including modules.\n",
    "# Exclude modules as well.\n",
    "BLACKLIST = type, ModuleType, FunctionType\n",
    "def getsize(obj):\n",
    "    \"\"\"sum size of object & members.\"\"\"\n",
    "    if isinstance(obj, BLACKLIST):\n",
    "        raise TypeError('getsize() does not take argument of type: '+ str(type(obj)))\n",
    "    seen_ids = set()\n",
    "    size = 0\n",
    "    objects = [obj]\n",
    "    while objects:\n",
    "        need_referents = []\n",
    "        for obj in objects:\n",
    "            if not isinstance(obj, BLACKLIST) and id(obj) not in seen_ids:\n",
    "                seen_ids.add(id(obj))\n",
    "                size += sys.getsizeof(obj)\n",
    "                need_referents.append(obj)\n",
    "        objects = get_referents(*need_referents)\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "secret-integration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21402"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getsize(ConvNet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-australia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
